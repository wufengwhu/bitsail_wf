<?xml version="1.0" encoding="UTF-8"?>
<configuration>
<property>
<name>dfs.use.dfs.network.topology</name>
<value>true</value>
</property>
<property>
<name>ipc.server.tcpnodelay</name>
<value>true</value>
</property>
<property>
<name>dfs.block.invalidate.limit</name>
<value>10000</value>
</property>
<property>
<name>dfs.client.https.need-auth</name>
<value>false</value>
</property>
<property>
<name>dfs.namenode.kerberos.https.principal</name>
<value>hdfs/hadoop.domain_hive.honor@DOMAIN_HIVE.HONOR</value>
</property>
<property>
<name>dfs.namenode.servicerpc.port</name>
<value>25006</value>
</property>
<property>
<name>oi.dfs.colocation.zookeeper.session-timeout.ms</name>
<value>90000</value>
</property>
<property>
<name>dfs.disk.balancer.max.disk.throughputInMBperSec</name>
<value>10</value>
</property>
<property>
<name>ipc.server.handler.queue.size</name>
<value>100</value>
</property>
<property>
<name>dfs.namenode.ec.policies.max.cellsize</name>
<value>4194304</value>
</property>
<property>
<name>dfs.namenode.replication.min</name>
<value>1</value>
</property>
<property>
<name>dfs.namenode.redundancy.considerLoad</name>
<value>true</value>
</property>
<property>
<name>dfs.client.socketcache.expiryMsec</name>
<value>3000</value>
</property>
<property>
<name>dfs.federation.router.admin-address</name>
<value></value>
</property>
<property>
<name>dfs.namenode.fs-limits.min-block-size</name>
<value>1048576</value>
</property>
<property>
<name>dfs.namenode.path.based.cache.block.map.allocation.percent</name>
<value>0.25f</value>
</property>
<property>
<name>dfs.client.failover.activeinfo.share.flag</name>
<value>false</value>
</property>
<property>
<name>dfs.permissions.ContentSummary.subAccess</name>
<value>true</value>
</property>
<property>
<name>hadoop.proxyuser.miner.groups</name>
<value>*</value>
</property>
<property>
<name>dfs.balancer.auto.exclude.datanodes</name>
<value></value>
</property>
<property>
<name>ipc.25000.decay-scheduler.backoff.responsetime.thresholds</name>
<value>10000,20000,30000,40000</value>
</property>
<property>
<name>dfs.namenode.replication.interval</name>
<value>3</value>
</property>
<property>
<name>dfs.az.enable</name>
<value>false</value>
</property>
<property>
<name>dfs.balancer.getBlocks.size</name>
<value>2147483648</value>
</property>
<property>
<name>dfs.balancer.auto.policy</name>
<value>blockpool</value>
</property>
<property>
<name>dfs.image.string-tables.expanded</name>
<value>true</value>
</property>
<property>
<name>dfs.namenode.directory-items.monitor</name>
<value>/tmp,/SparkJobHistory,/mr-history</value>
</property>
<property>
<name>dfs.client.failover.observer.auto-msync-period.hacluster</name>
<value>0ms</value>
</property>
<property>
<name>dfs.client.failover.random.order</name>
<value>true</value>
</property>
<property>
<name>dfs.datanode.transfer.socket.send.buffer.size</name>
<value>131072</value>
</property>
<property>
<name>dfs.client.block.write.retries</name>
<value>3</value>
</property>
<property>
<name>dfs.namenode.safemode.threshold-pct</name>
<value>0.999999</value>
</property>
<property>
<name>dfs.namenode.servicerpc-bind-host</name>
<value>node-master4lsmd</value>
</property>
<property>
<name>dfs.nameservices</name>
<value>hacluster</value>
</property>
<property>
<name>dfs.namenode.file.close.num-committed-allowed</name>
<value>0</value>
</property>
<property>
<name>dfs.namenode.reconstruction.pending.timeout-sec</name>
<value>900</value>
</property>
<property>
<name>ipc.server.max.response.size</name>
<value>1048576</value>
</property>
<property>
<name>ipc.25000.backoff.enable</name>
<value>false</value>
</property>
<property>
<name>dfs.namenode.directory-items.monitor.enabled</name>
<value>true</value>
</property>
<property>
<name>dfs.disk.balancer.auto.enabled</name>
<value>false</value>
</property>
<property>
<name>dfs.ha.tail-edits.period.observer</name>
<value>15</value>
</property>
<property>
<name>dfs.client.socket-timeout</name>
<value>600000</value>
</property>
<property>
<name>dfs.balancer.block-move.timeout</name>
<value>0</value>
</property>
<property>
<name>dfs.balancer.auto.maxDataNodesNum</name>
<value>5</value>
</property>
<property>
<name>dfs.namenode.replication.max-streams-hard-limit</name>
<value>128</value>
</property>
<property>
<name>dfs.auto.data.mover.enable</name>
<value>false</value>
</property>
<property>
<name>ipc.25000.faircallqueue.decay-scheduler.thresholds</name>
<value></value>
</property>
<property>
<name>net.topology.nodegroup.aware</name>
<value>false</value>
</property>
<property>
<name>dfs.client.delete.to.trash.paths</name>
<value></value>
</property>
<property>
<name>dfs.namenode.max.objects</name>
<value>0</value>
</property>
<property>
<name>dfs.router.nameservice</name>
<value>nsfed</value>
</property>
<property>
<name>dfs.bytes-per-checksum</name>
<value>512</value>
</property>
<property>
<name>dfs.cluster.administrators</name>
<value>hdfs hadoopmanager,supergroup,System_administrator_186</value>
</property>
<property>
<name>ha.failover-controller.new-active.rpc-timeout.ms</name>
<value>180000</value>
</property>
<property>
<name>dfs.client.read.shortcircuit</name>
<value>true</value>
</property>
<property>
<name>dfs.namenode.http-address.hacluster.3</name>
<value>node-master3jrzu:25002</value>
</property>
<property>
<name>dfs.namenode.http-address.hacluster.4</name>
<value>node-master4lsmd:25002</value>
</property>
<property>
<name>dfs.az.block.placement.ec.classname</name>
<value>org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant</value>
</property>
<property>
<name>dfs.namenode.jmx.url.prefix</name>
<value>https://node-master4lsmd:25003</value>
</property>
<property>
<name>dfs.activenamenode.checkpoint.interval</name>
<value>12</value>
</property>
<property>
<name>net.topology.impl</name>
<value>org.apache.hadoop.net.NetworkTopology</value>
</property>
<property>
<name>dfs.client.failover.sleep.base.millis</name>
<value>500</value>
</property>
<property>
<name>dfs.permissions.superusergroup</name>
<value></value>
</property>
<property>
<name>ipc.25000.faircallqueue.multiplexer.weights</name>
<value></value>
</property>
<property>
<name>dfs.client.socket.send.buffer.size</name>
<value>131072</value>
</property>
<property>
<name>dfs.balancer.getBlocks.min-block-size</name>
<value>10485760</value>
</property>
<property>
<name>dfs.namenode.heartbeat.recheck-interval</name>
<value>300000</value>
</property>
<property>
<name>ipc.25000.identity-provider.impl</name>
<value>org.apache.hadoop.ipc.UserIdentityProvider</value>
</property>
<property>
<name>dfs.namenode.safemode.extension</name>
<value>15000</value>
</property>
<property>
<name>dfs.client.failover.sleep.max.millis</name>
<value>15000</value>
</property>
<property>
<name>dfs.namenode.delegation.key.update-interval</name>
<value>86400000</value>
</property>
<property>
<name>dfs.client.failover.activeinfo.share.path</name>
<value>/tmp</value>
</property>
<property>
<name>fs.permissions.umask-mode</name>
<value>022</value>
</property>
<property>
<name>hadoop.zk.hostname.list</name>
<value>node-master5ndwv,node-master6rfkz,node-master7urvl,node-master8wjiq,node-master9woxv</value>
</property>
<property>
<name>dfs.journalnode.rpc.port</name>
<value>25012</value>
</property>
<property>
<name>dfs.namenode.fs-limits.max-blocks-per-file</name>
<value>1048576</value>
</property>
<property>
<name>ipc.25000.faircallqueue.priority-levels</name>
<value>4</value>
</property>
<property>
<name>dfs.client.block.write.replace-datanode-on-failure.enable</name>
<value>true</value>
</property>
<property>
<name>dfs.namenode.lifeline.handler.ratio</name>
<value>0.1</value>
</property>
<property>
<name>dfs.ha.zkfc.port</name>
<value>25015</value>
</property>
<property>
<name>net.topology.node.switch.mapping.impl</name>
<value>org.apache.hadoop.net.ScriptBasedMapping</value>
</property>
<property>
<name>dfs.storage.policy.enabled</name>
<value>true</value>
</property>
<property>
<name>ipc.call.queue.high.priority.capacity.factor</name>
<value>0.05</value>
</property>
<property>
<name>ipc.25000.decay-scheduler.backoff.responsetime.enable</name>
<value>false</value>
</property>
<property>
<name>ha.zookeeper.parent-znode</name>
<value>/hadoop-ha</value>
</property>
<property>
<name>dfs.datanode.block-pinning.enabled</name>
<value>false</value>
</property>
<property>
<name>dfs.encrypt.data.transfer.cipher.suites</name>
<value>AES/CTR/NoPadding</value>
</property>
<property>
<name>dfs.namenode.blocklocation.with.path</name>
<value>false</value>
</property>
<property>
<name>dfs.blockplacement.mandatory.rackgroup.name</name>
<value></value>
</property>
<property>
<name>dfs.encrypt.data.transfer.cipher.key.bitlength</name>
<value>256</value>
</property>
<property>
<name>dfs.balancer.dispatcherThreads</name>
<value>512</value>
</property>
<property>
<name>dfs.disk.balancer.top.nodes.number</name>
<value>5</value>
</property>
<property>
<name>dfs.namenode.stale.datanode.interval</name>
<value>30000</value>
</property>
<property>
<name>dfs.namenode.rpc-address.hacluster.3</name>
<value>node-master3jrzu:25000</value>
</property>
<property>
<name>dfs.namenode.rpc-address.hacluster.4</name>
<value>node-master4lsmd:25000</value>
</property>
<property>
<name>dfs.namenode.ec.system.default.policy</name>
<value>RS-6-3-1024k</value>
</property>
<property>
<name>dfs.replication.max</name>
<value>512</value>
</property>
<property>
<name>dfs.namenode.name.dir</name>
<value>/srv/BigData/data3/namenode</value>
</property>
<property>
<name>dfs.federation.router.store.driver.zk.parent-path</name>
<value></value>
</property>
<property>
<name>ipc.client.kill.max</name>
<value>10</value>
</property>
<property>
<name>dfs.balancer.block.filter.class</name>
<value>org.apache.hadoop.hdfs.server.balancer.BlockFilterWithNodeLabel</value>
</property>
<property>
<name>dfs.block.access.token.enable</name>
<value>true</value>
</property>
<property>
<name>dfs.datanode.fileio.profiling.sampling.percentage</name>
<value>20</value>
</property>
<property>
<name>dfs.namenode.lifeline.handler.count</name>
<value>16</value>
</property>
<property>
<name>dfs.balancer.auto.threshold</name>
<value>10</value>
</property>
<property>
<name>multi.namenode.flag</name>
<value>value</value>
</property>
<property>
<name>dfs.disk.balancer.auto.cron.expression</name>
<value>0 1 * * 6</value>
</property>
<property>
<name>dfs.mover.auto.hdfsfiles_or_dirs</name>
<value></value>
</property>
<property>
<name>dfs.hosts</name>
<value></value>
</property>
<property>
<name>dfs.datanode.synconclose</name>
<value>false</value>
</property>
<property>
<name>dfs.current.nameservice</name>
<value>hacluster</value>
</property>
<property>
<name>dfs.client.file-block-storage-locations.timeout.millis</name>
<value>600000</value>
</property>
<property>
<name>dfs.namenode.retrycache.heap.percent</name>
<value>0.03f</value>
</property>
<property>
<name>dfs.az.block.replicator.classname</name>
<value>org.apache.hadoop.hdfs.server.blockmanagement.AvailableSpaceBlockPlacementPolicy</value>
</property>
<property>
<name>dfs.image.compress</name>
<value>false</value>
</property>
<property>
<name>dfs.namenode.lifeline.rpc.port</name>
<value>25005</value>
</property>
<property>
<name>dfs.namenode.checkpoint.check.period</name>
<value>60</value>
</property>
<property>
<name>dfs.block.placement.xattr.list</name>
<value></value>
</property>
<property>
<name>dfs.namenode.service.handler.count</name>
<value>32</value>
</property>
<property>
<name>ipc.call.queue.high.priority.factor</name>
<value>0.75</value>
</property>
<property>
<name>ipc.25000.faircallqueue.decay-scheduler.decay-factor</name>
<value>0.5</value>
</property>
<property>
<name>dfs.namenode.active_standby.ids.hacluster</name>
<value>3,4</value>
</property>
<property>
<name>dfs.ha.namenodes.hacluster</name>
<value>3,4</value>
</property>
<property>
<name>dfs.namenode.startup.delay.block.deletion.sec</name>
<value>3600</value>
</property>
<property>
<name>dfs.client.socketcache.capacity</name>
<value>16</value>
</property>
<property>
<name>dfs.heartbeat.interval</name>
<value>1</value>
</property>
<property>
<name>dfs.balancer.auto.cron.expression</name>
<value>0 1 * * 6</value>
</property>
<property>
<name>dfs.auto-datamovement.policy.class</name>
<value>com.huawei.hadoop.hdfs.datamovement.policy.DefaultDataMovementPolicy</value>
</property>
<property>
<name>dfs.datanode.peer.stats.enabled</name>
<value>true</value>
</property>
<property>
<name>dfs.replication</name>
<value>3</value>
</property>
<property>
<name>dfs.ha.fencing.ssh.private-key-files</name>
<value>/home/omm/.ssh/id_rsa</value>
</property>
<property>
<name>dfs.namenode.audit.log.async</name>
<value>false</value>
</property>
<property>
<name>dfs.auto.data.mover.custome.actions</name>
<value></value>
</property>
<property>
<name>fs.defaultFS.for.router-based-federation</name>
<value></value>
</property>
<property>
<name>dfs.namenode.observer.ids.hacluster</name>
<value></value>
</property>
<property>
<name>dfs.namenode.audit.log.debug.cmdlist</name>
<value>open,getfileinfo,getAclStatus</value>
</property>
<property>
<name>dfs.namenode.az.health.threshold</name>
<value></value>
</property>
<property>
<name>dfs.client.failover.activeinfo.share.io.timeout.sec</name>
<value>5</value>
</property>
<property>
<name>dfs.mover.auto.cron.expression</name>
<value>0 * * * *</value>
</property>
<property>
<name>dfs.namenode.default.expression</name>
<value></value>
</property>
<property>
<name>dfs.namenode.http.policy</name>
<value>HTTPS_ONLY</value>
</property>
<property>
<name>dfs.namenode.acls.enabled</name>
<value>true</value>
</property>
<property>
<name>dfs.journalnode.keytab.file</name>
<value>/opt/Bigdata/FusionInsight_HD_8.0.2.1/install/FusionInsight-Hadoop-3.1.1/hadoop/keytabs/hdfs/hdfs.keytab</value>
</property>
<property>
<name>dfs.client.metadata.cache.enabled</name>
<value>false</value>
</property>
<property>
<name>ha.failover-controller.graceful-fence.rpc-timeout.ms</name>
<value>180000</value>
</property>
<property>
<name>dfs.namenode.datanode.registration.ip-hostname-check</name>
<value>true</value>
</property>
<property>
<name>dfs.journalnode.kerberos.principal</name>
<value>hdfs/hadoop.domain_hive.honor@DOMAIN_HIVE.HONOR</value>
</property>
<property>
<name>dfs.namenode.edits.noeditlogchannelflush</name>
<value>false</value>
</property>
<property>
<name>dfs.web.authentication.kerberos.keytab</name>
<value>/opt/Bigdata/FusionInsight_HD_8.0.2.1/install/FusionInsight-Hadoop-3.1.1/hadoop/keytabs/hdfs/HTTP.keytab</value>
</property>
<property>
<name>dfs.mover.auto.enable</name>
<value>false</value>
</property>
<property>
<name>ipc.call.queue.high.priority.methods</name>
<value>msync</value>
</property>
<property>
<name>dfs.http.policy</name>
<value>HTTPS_ONLY</value>
</property>
<property>
<name>dfs.balancer.max-size-to-move</name>
<value>32212254720</value>
</property>
<property>
<name>dfs.client.failover.proxy.provider.hacluster</name>
<value>org.apache.hadoop.hdfs.server.namenode.ha.AdaptiveFailoverProxyProvider</value>
</property>
<property>
<name>dfs.namenode.safemode.min.datanodes</name>
<value>0</value>
</property>
<property>
<name>dfs.datanode.kerberos.principal</name>
<value>hdfs/hadoop.domain_hive.honor@DOMAIN_HIVE.HONOR</value>
</property>
<property>
<name>oi.dfs.colocation.zookeeper.lock.limit</name>
<value>10</value>
</property>
<property>
<name>dfs.namenode.available-space-block-placement-policy.balance-local-node</name>
<value>false</value>
</property>
<property>
<name>dfs.webhdfs.enabled</name>
<value>true</value>
</property>
<property>
<name>dfs.namenode.delegation.token.max-lifetime</name>
<value>604800000</value>
</property>
<property>
<name>dfs.auto.data.mover.cron.expression</name>
<value>0 * * * *</value>
</property>
<property>
<name>dfs.namenode.avoid.write.stale.datanode</name>
<value>true</value>
</property>
<property>
<name>dfs.namenode.kerberos.principal</name>
<value>hdfs/hadoop.domain_hive.honor@DOMAIN_HIVE.HONOR</value>
</property>
<property>
<name>dfs.block.placement.ec.classname</name>
<value>org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant</value>
</property>
<property>
<name>dfs.namenode.num.extra.edits.retained</name>
<value>1000000</value>
</property>
<property>
<name>ipc.25000.callqueue.impl</name>
<value>java.util.concurrent.LinkedBlockingQueue</value>
</property>
<property>
<name>ipc.client.connect.max.retries.on.timeouts</name>
<value>45</value>
</property>
<property>
<name>dfs.ha.tail-edits.in-progress</name>
<value>false</value>
</property>
<property>
<name>dfs.namenode.available-space-block-placement-policy.balanced-space-preference-fraction</name>
<value>0.6</value>
</property>
<property>
<name>dfs.client-write-packet-size</name>
<value>262144</value>
</property>
<property>
<name>dfs.namenode.checkpoint.txns</name>
<value>5000000</value>
</property>
<property>
<name>dfs.namenode.kerberos.principal.pattern</name>
<value>*</value>
</property>
<property>
<name>dfs.namenode.replication.max-streams</name>
<value>64</value>
</property>
<property>
<name>dfs.namenode.keytab.file</name>
<value>/opt/Bigdata/FusionInsight_HD_8.0.2.1/install/FusionInsight-Hadoop-3.1.1/hadoop/keytabs/hdfs/hdfs.keytab</value>
</property>
<property>
<name>ipc.client.idlethreshold</name>
<value>4000</value>
</property>
<property>
<name>dfs.client.failover.connection.retries.on.timeouts</name>
<value>0</value>
</property>
<property>
<name>dfs.client.close.ack-timeout</name>
<value>900000</value>
</property>
<property>
<name>dfs.namenode.replication.work.multiplier.per.iteration</name>
<value>32</value>
</property>
<property>
<name>dfs.client.metadata.cache.pattern</name>
<value></value>
</property>
<property>
<name>dfs.internal.nameservices</name>
<value>hacluster</value>
</property>
<property>
<name>dfs.image.compression.codec</name>
<value>org.apache.hadoop.io.compress.DefaultCodec</value>
</property>
<property>
<name>dfs.datanode.socket.write.timeout</name>
<value>600000</value>
</property>
<property>
<name>dfs.namenode.accesstime.precision</name>
<value>3600000</value>
</property>
<property>
<name>dfs.namenode.redundancy.considerLoad.factor</name>
<value>4</value>
</property>
<property>
<name>dfs.namenode.lifeline.rpc-bind-host</name>
<value>node-master4lsmd</value>
</property>
<property>
<name>dfs.image.transfer.timeout</name>
<value>600000</value>
</property>
<property>
<name>dfs.stream-buffer-size</name>
<value>4096</value>
</property>
<property>
<name>dfs.namenode.invalidate.work.pct.per.iteration</name>
<value>0.32</value>
</property>
<property>
<name>dfs.datanode.outliers.report.interval</name>
<value>1800000</value>
</property>
<property>
<name>dfs.encrypt.data.transfer.algorithm</name>
<value>3des</value>
</property>
<property>
<name>dfs.client.metadata.cache.expiry.sec</name>
<value>60s</value>
</property>
<property>
<name>dfs.namenode.https.port</name>
<value>25003</value>
</property>
<property>
<name>dfs.namenode.inode.attributes.provider.class</name>
<value>com.huawei.hadoop.adapter.hdfs.plugin.HWRangerHdfsAuthorizer</value>
</property>
<property>
<name>dfs.block.replicator.classname</name>
<value>org.apache.hadoop.hdfs.server.blockmanagement.AvailableSpaceBlockPlacementPolicy</value>
</property>
<property>
<name>dfs.namenode.fs-limits.max-directory-items</name>
<value>1048576</value>
</property>
<property>
<name>dfs.ha.log-roll.period</name>
<value>120</value>
</property>
<property>
<name>dfs.ha.namenode.id</name>
<value>4</value>
</property>
<property>
<name>dfs.datanode.transfer.socket.recv.buffer.size</name>
<value>131072</value>
</property>
<property>
<name>audit.service.name</name>
<value>HDFS</value>
</property>
<property>
<name>dfs.namenode.lifeline.rpc-address.hacluster.3</name>
<value>node-master3jrzu:25005</value>
</property>
<property>
<name>dfs.namenode.lifeline.rpc-address.hacluster.4</name>
<value>node-master4lsmd:25005</value>
</property>
<property>
<name>dfs.net.topology.az.graph</name>
<value></value>
</property>
<property>
<name>dfs.observer.read.enable</name>
<value>true</value>
</property>
<property>
<name>ipc.namenode-rpc-port.need.replace</name>
<value>true</value>
</property>
<property>
<name>dfs.namenode.ec.ignore.compatibility.check.during-upgrade</name>
<value>true</value>
</property>
<property>
<name>dfs.balancer.auto.maxIdleIterations</name>
<value>5</value>
</property>
<property>
<name>dfs.balancer.auto.enable</name>
<value>false</value>
</property>
<property>
<name>oi.dfs.colocation.zookeeper.quorum</name>
<value>node-master5ndwv:24002,node-master6rfkz:24002,node-master7urvl:24002,node-master8wjiq:24002,node-master9woxv:24002</value>
</property>
<property>
<name>dfs.disk.balancer.block.tolerance.percent</name>
<value>10</value>
</property>
<property>
<name>ipc.25000.scheduler.impl</name>
<value></value>
</property>
<property>
<name>dfs.namenode.shared.edits.dir.hacluster</name>
<value>qjournal://10.68.192.208:25012;10.68.192.41:25012;10.68.194.100:25012/hacluster</value>
</property>
<property>
<name>dfs.datanode.balance.max.concurrent.moves</name>
<value>32</value>
</property>
<property>
<name>dfs.namenode.num.checkpoints.retained</name>
<value>3</value>
</property>
<property>
<name>dfs.namenode.state.context.enabled</name>
<value>false</value>
</property>
<property>
<name>dfs.permissions.enabled</name>
<value>true</value>
</property>
<property>
<name>ha.zookeeper.quorum</name>
<value>node-master5ndwv:24002,node-master6rfkz:24002,node-master7urvl:24002,node-master8wjiq:24002,node-master9woxv:24002</value>
</property>
<property>
<name>dfs.rackgroup.nextpolicy</name>
<value>org.apache.hadoop.hdfs.server.blockmanagement.AvailableSpaceBlockPlacementPolicy</value>
</property>
<property>
<name>dfs.namenode.http.port</name>
<value>25002</value>
</property>
<property>
<name>dfs.disk.balancer.plan.threshold.percent</name>
<value>10</value>
</property>
<property>
<name>dfs.domain.socket.path</name>
<value>/var/run/FusionInsight-HDFS/dn_socket</value>
</property>
<property>
<name>dfs.disk.balancer.max.disk.errors</name>
<value>5</value>
</property>
<property>
<name>dfs.namenode.handler.count</name>
<value>128</value>
</property>
<property>
<name>dfs.qjournal.write-txns.timeout.ms</name>
<value>20000</value>
</property>
<property>
<name>dfs.image.transfer.bandwidthPerSec</name>
<value>104857600</value>
</property>
<property>
<name>dfs.client.block.write.replace-datanode-on-failure.min-replication</name>
<value>1</value>
</property>
<property>
<name>dfs.namenode.observer.enable</name>
<value>false</value>
</property>
<property>
<name>dfs.namenode.upgrade.nodelabel.xattr</name>
<value>true</value>
</property>
<property>
<name>dfs.blocksize</name>
<value>134217728</value>
</property>
<property>
<name>ha.failover-controller.cli-check.rpc-timeout.ms</name>
<value>180000</value>
</property>
<property>
<name>dfs.encrypt.data.transfer</name>
<value>false</value>
</property>
<property>
<name>dfs.namenode.write.stale.datanode.ratio</name>
<value>0.5f</value>
</property>
<property>
<name>dfs.client.failover.max.attempts</name>
<value>20</value>
</property>
<property>
<name>dfs.client.block.write.replace-datanode-on-failure.replication</name>
<value>2</value>
</property>
<property>
<name>dfs.journalnode.kerberos.internal.spnego.principal</name>
<value>HTTP/_HOST@DOMAIN_HIVE.HONOR</value>
</property>
<property>
<name>dfs.client.read.shortcircuit.skip.checksum</name>
<value>true</value>
</property>
<property>
<name>dfs.nameservices.mappings</name>
<value>[{"name":"hacluster","roleInstances":["3","4"],"relationInstances":["10.68.192.208","10.68.192.41","10.68.194.100"]}]</value>
</property>
<property>
<name>dfs.namenode.quota.init-threads</name>
<value>32</value>
</property>
<property>
<name>dfs.client.failover.proxy.provider.nsfed</name>
<value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
</property>
<property>
<name>az.names</name>
<value></value>
</property>
<property>
<name>dfs.namenode.https-address.hacluster.3</name>
<value>node-master3jrzu:25003</value>
</property>
<property>
<name>dfs.namenode.https-address.hacluster.4</name>
<value>node-master4lsmd:25003</value>
</property>
<property>
<name>dfs.namenode.delegation.token.renew-interval</name>
<value>86400000</value>
</property>
<property>
<name>dfs.image.loader.thread</name>
<value>0</value>
</property>
<property>
<name>dfs.web.authentication.kerberos.principal</name>
<value>HTTP/_HOST@DOMAIN_HIVE.HONOR</value>
</property>
<property>
<name>hadoop.http.authentication.cookie.domain</name>
<value></value>
</property>
<property>
<name>dfs.namenode.kerberos.internal.spnego.principal</name>
<value>HTTP/_HOST@DOMAIN_HIVE.HONOR</value>
</property>
<property>
<name>dfs.namenode.rpc-bind-host</name>
<value>node-master4lsmd</value>
</property>
<property>
<name>dfs.client.failover.connection.retries</name>
<value>0</value>
</property>
<property>
<name>dfs.namenode.plugins</name>
<value></value>
</property>
<property>
<name>dfs.client.metadata.cache.max.entries</name>
<value>65536</value>
</property>
<property>
<name>dfs.federation.datanode</name>
<value>node-group-1yyuz0008:25008,node-group-1yyuz0007:25008,node-group-1yyuz0009:25008,node-group-1yyuz0010:25008,node-group-1kby70009:25008,node-group-1kby70007:25008,node-group-1kby70008:25008,node-group-1kby70001:25008,node-group-1kby70002:25008,node-group-1kby70005:25008,node-group-1kby70006:25008,node-group-1uxkp0009:25008,node-group-1kby70020:25008,node-group-1uxkp0010:25008,node-group-1uxkp0011:25008,node-group-1uxkp0012:25008,node-group-1fkzy0008:25008,node-group-1fkzy0009:25008,node-group-1fkzy0010:25008,node-group-1fkzy0002:25008,node-group-1fkzy0003:25008,node-group-1kby70003:25008,node-group-1kby70004:25008,node-group-1kby70018:25008,node-group-1kby70019:25008,node-group-1kby70012:25008,node-group-1kby70013:25008,node-group-1kby70010:25008,node-group-1kby70011:25008,node-group-1kby70016:25008,node-group-1kby70017:25008,node-group-1kby70014:25008,node-group-1kby70015:25008,node-group-1uxkp0004:25008,node-group-1uxkp0005:25008,node-group-1uxkp0006:25008,node-group-1uxkp0007:25008,node-group-1uxkp0008:25008,node-group-1yyuz0004:25008,node-group-1yyuz0003:25008,node-group-1yyuz0006:25008,node-group-1yyuz0005:25008,node-group-1yyuz0002:25008,node-group-1yyuz0001:25008,node-group-1uzq80007:25008,node-group-1uzq80006:25008,node-group-1uzq80005:25008,node-group-1uzq80004:25008,node-group-1uzq80003:25008,node-group-1uzq80002:25008,node-group-1uzq80001:25008,node-group-1uzq80009:25008,node-group-1uzq80008:25008,node-group-1od0u0020:25008,node-group-1uzq80010:25008,node-group-1uxkp0001:25008,node-group-1uxkp0002:25008,node-group-1uxkp0003:25008,node-group-1uzq80018:25008,node-group-1uzq80017:25008,node-group-1uzq80016:25008,node-group-1uzq80015:25008,node-group-1fkzy0001:25008,node-group-1fkzy0006:25008,node-group-1fkzy0007:25008,node-group-1fkzy0004:25008,node-group-1fkzy0005:25008,node-group-1uxkp0013:25008,node-group-1uxkp0014:25008,node-group-1uxkp0015:25008,node-group-1zi8v0013:25008,node-group-1uxkp0016:25008,node-group-1zi8v0012:25008,node-group-1uxkp0017:25008,node-group-1zi8v0011:25008,node-group-1uxkp0018:25008,node-group-1zi8v0010:25008,node-group-1uxkp0019:25008,node-group-1zi8v0017:25008,node-group-1zi8v0016:25008,node-group-1zi8v0015:25008,node-group-1zi8v0014:25008,node-group-1zi8v0019:25008,node-group-1zi8v0018:25008,node-group-1uxkp0020:25008,node-group-1zi8v0020:25008,node-group-1zi8v0002:25008,node-group-1zi8v0001:25008,node-group-1uzq80014:25008,node-group-1uzq80013:25008,node-group-1uzq80012:25008,node-group-1uzq80011:25008,node-group-1uzq80019:25008,node-group-1uzq80020:25008,node-group-1od0u0007:25008,node-group-1zi8v0006:25008,node-group-1zi8v0005:25008,node-group-1zi8v0004:25008,node-group-1zi8v0003:25008,node-group-1od0u0018:25008,node-group-1zi8v0009:25008,node-group-1od0u0017:25008,node-group-1zi8v0008:25008,node-group-1zi8v0007:25008,node-group-1od0u0019:25008,node-group-1od0u0014:25008,node-group-1od0u0013:25008,node-group-1od0u0016:25008,node-group-1od0u0015:25008,node-group-1od0u0010:25008,node-group-1xurf0002:25008,node-group-1pt6b0015:25008,node-group-1pt6b0016:25008,node-group-1pt6b0017:25008,node-group-1pt6b0010:25008,node-group-1pt6b0011:25008,node-group-1pt6b0012:25008,node-group-1pt6b0013:25008,node-group-1pt6b0014:25008,node-group-1pt6b0004:25008,node-group-1pt6b0005:25008,node-group-1pt6b0006:25008,node-group-1pt6b0007:25008,node-group-1pt6b0008:25008,node-group-1pt6b0009:25008,node-group-1xurf0020:25008,node-group-1pt6b0001:25008,node-group-1pt6b0002:25008,node-group-1pt6b0003:25008,node-group-1xurf0014:25008,node-group-1xurf0015:25008,node-group-1xurf0016:25008,node-group-1xurf0017:25008,node-group-1xurf0018:25008,node-group-1xurf0019:25008,node-group-1xurf0010:25008,node-group-1xurf0011:25008,node-group-1xurf0012:25008,node-group-1xurf0013:25008,node-group-1mpo60018:25008,node-group-1mpo60017:25008,node-group-1pt6b0018:25008,node-group-1eqsl0009:25008,node-group-1bkre0002:25008,node-group-1mpo60020:25008,node-group-1bkre0003:25008,node-group-1bkre0001:25008,node-group-1bkre0006:25008,node-group-1bkre0007:25008,node-group-1bkre0004:25008,node-group-1bkre0005:25008,node-group-1od0u0012:25008,node-group-1od0u0011:25008,node-group-1od0u0006:25008,node-group-1od0u0009:25008,node-group-1od0u0008:25008,node-group-1od0u0003:25008,node-group-1od0u0002:25008,node-group-1od0u0005:25008,node-group-1od0u0004:25008,node-group-1od0u0001:25008,node-group-1eqsl0004:25008,node-group-1eqsl0003:25008,node-group-1eqsl0006:25008,node-group-1eqsl0005:25008,node-group-1eqsl0002:25008,node-group-1eqsl0001:25008,node-group-1xurf0003:25008,node-group-1xurf0004:25008,node-group-1xurf0005:25008,node-group-1xurf0006:25008,node-group-1xurf0008:25008,node-group-1xurf0009:25008,node-group-1pt6b0020:25008,node-group-1xurf0001:25008,node-group-1pt6b0019:25008,node-group-1mpo60019:25008,node-group-1mpo60014:25008,node-group-1mpo60013:25008,node-group-1mpo60016:25008,node-group-1mpo60015:25008,node-group-1eqsl0019:25008,node-group-1eqsl0018:25008,node-group-1eqsl0015:25008,node-group-1eqsl0014:25008,node-group-1eqsl0017:25008,node-group-1eqsl0016:25008,node-group-1eqsl0011:25008,node-group-1eqsl0010:25008,node-group-1eqsl0013:25008,node-group-1eqsl0012:25008,node-group-1mpo60007:25008,node-group-1mpo60006:25008,node-group-1mpo60009:25008,node-group-1mpo60008:25008,node-group-1mpo60003:25008,node-group-1mpo60002:25008,node-group-1mpo60005:25008,node-group-1mpo60004:25008,node-group-1mpo60010:25008,node-group-1mpo60012:25008,node-group-1mpo60011:25008,node-group-1eqsl0008:25008,node-group-1eqsl0007:25008,node-group-1bkre0009:25008,node-group-1bkre0010:25008,node-group-1bkre0013:25008,node-group-1bkre0014:25008,node-group-1bkre0011:25008,node-group-1bkre0012:25008,node-group-1bkre0017:25008,node-group-1bkre0018:25008,node-group-1bkre0015:25008,node-group-1bkre0016:25008,node-group-1bkre0019:25008,node-group-1eqsl0020:25008,node-group-1bkre0008:25008,node-group-1bkre0020:25008,node-group-1mpo60001:25008</value>
</property>
<property>
<name>dfs.namenode.retrycache.expirytime.millis</name>
<value>600000</value>
</property>
<property>
<name>dfs.ha.fencing.ssh.connect-timeout</name>
<value>10000</value>
</property>
<property>
<name>dfs.namenode.fs-limits.max-component-length</name>
<value>7999</value>
</property>
<property>
<name>dfs.ha.fencing.methods</name>
<value>shell(/bin/true)</value>
</property>
<property>
<name>dfs.namenode.enable.retrycache</name>
<value>true</value>
</property>
<property>
<name>dfs.client.block.write.replace-datanode-on-failure.policy</name>
<value>ALWAYS</value>
</property>
<property>
<name>dfs.balancer.auto.stop.cron.expression</name>
<value></value>
</property>
<property>
<name>dfs.ha.tail-edits.period</name>
<value>60000</value>
</property>
<property>
<name>ipc.25000.faircallqueue.decay-scheduler.period-ms</name>
<value>5000</value>
</property>
<property>
<name>dfs.skip.health-check.nameservices</name>
<value></value>
</property>
<property>
<name>dfs.namenode.edits.dir</name>
<value>/srv/BigData/namenode</value>
</property>
<property>
<name>dfs.image.loader.inode.partition</name>
<value>1048576</value>
</property>
<property>
<name>dfs.balancer.auto.bandwidthPerSec</name>
<value>20</value>
</property>
<property>
<name>dfs.namenode.rpc.port</name>
<value>25000</value>
</property>
<property>
<name>dfs.namenode.servicerpc-address.hacluster.3</name>
<value>node-master3jrzu:25006</value>
</property>
<property>
<name>dfs.namenode.name.dir.restore</name>
<value>true</value>
</property>
<property>
<name>dfs.namenode.servicerpc-address.hacluster.4</name>
<value>node-master4lsmd:25006</value>
</property>
<property>
<name>dfs.datanode.lifeline.interval.seconds</name>
<value></value>
</property>
<property>
<name>dfs.support.append</name>
<value>true</value>
</property>
<property>
<name>dfs.datanode.socket.reuse.keepalive</name>
<value>4000</value>
</property>
<property>
<name>dfs.namenode.checkpoint.period</name>
<value>3600</value>
</property>
<property>
<name>dfs.client.read.striped.threadpool.size</name>
<value>256</value>
</property>
<property>
<name>dfs.ha.automatic-failover.enabled</name>
<value>true</value>
</property>
</configuration>
